{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "best of COVID X-ray.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN5oyfLS3/PEvySK+pl2n4m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suyash091/Covid-19-diagnosis-engine/blob/master/best_of_COVID_X_ray%20epoch%20353.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm4aFQVVw925",
        "colab_type": "code",
        "outputId": "1272e0dd-b9e1-4ce7-bcfa-a0d0d64a34f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!git clone 'https://github.com/suyash091/covid-chestxray-dataset'\n",
        "!git clone https://github.com/qubvel/efficientnet.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'covid-chestxray-dataset'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/51)\u001b[K\rremote: Counting objects:   3% (2/51)\u001b[K\rremote: Counting objects:   5% (3/51)\u001b[K\rremote: Counting objects:   7% (4/51)\u001b[K\rremote: Counting objects:   9% (5/51)\u001b[K\rremote: Counting objects:  11% (6/51)\u001b[K\rremote: Counting objects:  13% (7/51)\u001b[K\rremote: Counting objects:  15% (8/51)\u001b[K\rremote: Counting objects:  17% (9/51)\u001b[K\rremote: Counting objects:  19% (10/51)\u001b[K\rremote: Counting objects:  21% (11/51)\u001b[K\rremote: Counting objects:  23% (12/51)\u001b[K\rremote: Counting objects:  25% (13/51)\u001b[K\rremote: Counting objects:  27% (14/51)\u001b[K\rremote: Counting objects:  29% (15/51)\u001b[K\rremote: Counting objects:  31% (16/51)\u001b[K\rremote: Counting objects:  33% (17/51)\u001b[K\rremote: Counting objects:  35% (18/51)\u001b[K\rremote: Counting objects:  37% (19/51)\u001b[K\rremote: Counting objects:  39% (20/51)\u001b[K\rremote: Counting objects:  41% (21/51)\u001b[K\rremote: Counting objects:  43% (22/51)\u001b[K\rremote: Counting objects:  45% (23/51)\u001b[K\rremote: Counting objects:  47% (24/51)\u001b[K\rremote: Counting objects:  49% (25/51)\u001b[K\rremote: Counting objects:  50% (26/51)\u001b[K\rremote: Counting objects:  52% (27/51)\u001b[K\rremote: Counting objects:  54% (28/51)\u001b[K\rremote: Counting objects:  56% (29/51)\u001b[K\rremote: Counting objects:  58% (30/51)\u001b[K\rremote: Counting objects:  60% (31/51)\u001b[K\rremote: Counting objects:  62% (32/51)\u001b[K\rremote: Counting objects:  64% (33/51)\u001b[K\rremote: Counting objects:  66% (34/51)\u001b[K\rremote: Counting objects:  68% (35/51)\u001b[K\rremote: Counting objects:  70% (36/51)\u001b[K\rremote: Counting objects:  72% (37/51)\u001b[K\rremote: Counting objects:  74% (38/51)\u001b[K\rremote: Counting objects:  76% (39/51)\u001b[K\rremote: Counting objects:  78% (40/51)\u001b[K\rremote: Counting objects:  80% (41/51)\u001b[K\rremote: Counting objects:  82% (42/51)\u001b[K\rremote: Counting objects:  84% (43/51)\u001b[K\rremote: Counting objects:  86% (44/51)\u001b[K\rremote: Counting objects:  88% (45/51)\u001b[K\rremote: Counting objects:  90% (46/51)\u001b[K\rremote: Counting objects:  92% (47/51)\u001b[K\rremote: Counting objects:  94% (48/51)\u001b[K\rremote: Counting objects:  96% (49/51)\u001b[K\rremote: Counting objects:  98% (50/51)\u001b[K\rremote: Counting objects: 100% (51/51)\u001b[K\rremote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 820 (delta 4), reused 0 (delta 0), pack-reused 769\u001b[K\n",
            "Receiving objects: 100% (820/820), 152.42 MiB | 14.42 MiB/s, done.\n",
            "Resolving deltas: 100% (242/242), done.\n",
            "Cloning into 'efficientnet'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 292 (delta 4), reused 5 (delta 1), pack-reused 280\u001b[K\n",
            "Receiving objects: 100% (292/292), 835.16 KiB | 926.00 KiB/s, done.\n",
            "Resolving deltas: 100% (160/160), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W0aH_hRHM96",
        "colab_type": "code",
        "outputId": "0a15915b-edee-4a85-923c-705d49ceab84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "import random\n",
        "seed(42)\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "random.seed(42)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "\n",
        "import efficientnet.efficientnet.keras as efn\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLCvVvucPl-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.optimizers import SGD, adam, Adadelta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m_j1ourhGHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target(string):\n",
        "  if string=='COVID-19':\n",
        "    return string\n",
        "  elif string=='No Finding':\n",
        "    return 'Nothing'\n",
        "  else:\n",
        "    return \"Others\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqJ6kgZ4K_e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('/content/covid-chestxray-dataset/metadata.csv')\n",
        "df= df[['filename','finding']]\n",
        "df['finding']=df['finding'].apply(target)\n",
        "dfother=pd.read_csv('/content/covid-chestxray-dataset/Others.csv')\n",
        "dfother.index +=len(df)\n",
        "dfnothing=pd.read_csv('/content/covid-chestxray-dataset/Nothing.csv')\n",
        "dfnothing.index +=int(len(df)+len(dfother))\n",
        "dfbal=pd.read_csv('/content/covid-chestxray-dataset/added.csv')\n",
        "dfbal.index +=int(len(df)+len(dfother)+len(dfnothing))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkoCT6IjfA3M",
        "colab_type": "code",
        "outputId": "acdad0da-fb4b-4ae6-8b73-db049d5c1849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "frames = [df, dfother, dfnothing, dfbal]\n",
        "\n",
        "df = pd.concat(frames)\n",
        "df= df[['filename','finding']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgKPpScmggrV",
        "colab_type": "code",
        "outputId": "08a8bd2c-8640-4873-b643-7376ecee81fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>finding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>365</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>364</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>person1003_virus_1685.jpeg</td>\n",
              "      <td>Others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          filename finding\n",
              "count                          365     365\n",
              "unique                         364       3\n",
              "top     person1003_virus_1685.jpeg  Others\n",
              "freq                             2     123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxJE9q_-LG_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysV7QHL6Lmxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biKGw1JULaov",
        "colab_type": "code",
        "outputId": "1bfc4cca-afa2-4026-ccd5-69e2d4edbe59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzlmkEEbMQWw",
        "colab_type": "code",
        "outputId": "192e4063-5a8b-4bf5-cc2d-0a651a7c902e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.finding.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['COVID-19', 'Others', 'Nothing'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZhZIZVGMVLM",
        "colab_type": "code",
        "outputId": "e09c38b0-9fc5-423a-a21b-576eea99d02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df[df['finding']=='COVID-19'])-len(df[df['finding']=='Others'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze5C7xl_HAsN",
        "colab_type": "code",
        "outputId": "c16bf4f8-908d-493e-fb43-358f6c2829b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        validation_split=0.1)\n",
        "\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=df,\n",
        "        directory='/content/covid-chestxray-dataset/images',\n",
        "        x_col=\"filename\",\n",
        "        y_col='finding',\n",
        "        target_size=(1024, 1024),\n",
        "        batch_size=16,\n",
        "        subset = 'training' ,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=df,\n",
        "        directory='/content/covid-chestxray-dataset/images',\n",
        "        x_col=\"filename\",\n",
        "        y_col='finding',\n",
        "        target_size=(1024, 1024),\n",
        "        batch_size=16,\n",
        "        subset=\"validation\",\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 328 validated image filenames belonging to 3 classes.\n",
            "Found 36 validated image filenames belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhOG3f3sHbTr",
        "colab_type": "code",
        "outputId": "b493b3b4-ae34-4f6c-ac24-5d75004bd7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "efficient_net = efn.EfficientNetB7(\n",
        "    weights='imagenet',\n",
        "    input_shape=(1024,1024,3),\n",
        "    include_top=False\n",
        ")\n",
        "efficient_net.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.5125 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.525 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.5375 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.5625 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "258441216/258434480 [==============================] - 16s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YhgkCoVEHWN",
        "colab_type": "code",
        "outputId": "02064636-231a-4ec8-fb15-2dae66c129eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "efficient_net.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"efficientnet-b7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1024, 1024, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv (Conv2D)              (None, 512, 512, 64) 1728        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "stem_bn (BatchNormalization)    (None, 512, 512, 64) 256         stem_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "stem_activation (Activation)    (None, 512, 512, 64) 0           stem_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1a_dwconv (DepthwiseConv2D (None, 512, 512, 64) 576         stem_activation[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1a_bn (BatchNormalization) (None, 512, 512, 64) 256         block1a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1a_activation (Activation) (None, 512, 512, 64) 0           block1a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_squeeze (GlobalAvera (None, 64)           0           block1a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reshape (Reshape)    (None, 1, 1, 64)     0           block1a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reduce (Conv2D)      (None, 1, 1, 16)     1040        block1a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_expand (Conv2D)      (None, 1, 1, 64)     1088        block1a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_excite (Multiply)    (None, 512, 512, 64) 0           block1a_activation[0][0]         \n",
            "                                                                 block1a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_conv (Conv2D)   (None, 512, 512, 32) 2048        block1a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_bn (BatchNormal (None, 512, 512, 32) 128         block1a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1b_dwconv (DepthwiseConv2D (None, 512, 512, 32) 288         block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_bn (BatchNormalization) (None, 512, 512, 32) 128         block1b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1b_activation (Activation) (None, 512, 512, 32) 0           block1b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_squeeze (GlobalAvera (None, 32)           0           block1b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_excite (Multiply)    (None, 512, 512, 32) 0           block1b_activation[0][0]         \n",
            "                                                                 block1b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_project_conv (Conv2D)   (None, 512, 512, 32) 1024        block1b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_project_bn (BatchNormal (None, 512, 512, 32) 128         block1b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1b_drop (FixedDropout)     (None, 512, 512, 32) 0           block1b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_add (Add)               (None, 512, 512, 32) 0           block1b_drop[0][0]               \n",
            "                                                                 block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_dwconv (DepthwiseConv2D (None, 512, 512, 32) 288         block1b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block1c_bn (BatchNormalization) (None, 512, 512, 32) 128         block1c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1c_activation (Activation) (None, 512, 512, 32) 0           block1c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_squeeze (GlobalAvera (None, 32)           0           block1c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1c_se_excite (Multiply)    (None, 512, 512, 32) 0           block1c_activation[0][0]         \n",
            "                                                                 block1c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1c_project_conv (Conv2D)   (None, 512, 512, 32) 1024        block1c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1c_project_bn (BatchNormal (None, 512, 512, 32) 128         block1c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1c_drop (FixedDropout)     (None, 512, 512, 32) 0           block1c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1c_add (Add)               (None, 512, 512, 32) 0           block1c_drop[0][0]               \n",
            "                                                                 block1b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block1d_dwconv (DepthwiseConv2D (None, 512, 512, 32) 288         block1c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block1d_bn (BatchNormalization) (None, 512, 512, 32) 128         block1d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1d_activation (Activation) (None, 512, 512, 32) 0           block1d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_squeeze (GlobalAvera (None, 32)           0           block1d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1d_se_excite (Multiply)    (None, 512, 512, 32) 0           block1d_activation[0][0]         \n",
            "                                                                 block1d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1d_project_conv (Conv2D)   (None, 512, 512, 32) 1024        block1d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1d_project_bn (BatchNormal (None, 512, 512, 32) 128         block1d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1d_drop (FixedDropout)     (None, 512, 512, 32) 0           block1d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1d_add (Add)               (None, 512, 512, 32) 0           block1d_drop[0][0]               \n",
            "                                                                 block1c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_conv (Conv2D)    (None, 512, 512, 192 6144        block1d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_bn (BatchNormali (None, 512, 512, 192 768         block2a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_activation (Acti (None, 512, 512, 192 0           block2a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv (DepthwiseConv2D (None, 256, 256, 192 1728        block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2a_bn (BatchNormalization) (None, 256, 256, 192 768         block2a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2a_activation (Activation) (None, 256, 256, 192 0           block2a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_squeeze (GlobalAvera (None, 192)          0           block2a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_excite (Multiply)    (None, 256, 256, 192 0           block2a_activation[0][0]         \n",
            "                                                                 block2a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_conv (Conv2D)   (None, 256, 256, 48) 9216        block2a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_bn (BatchNormal (None, 256, 256, 48) 192         block2a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_conv (Conv2D)    (None, 256, 256, 288 13824       block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_bn (BatchNormali (None, 256, 256, 288 1152        block2b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_activation (Acti (None, 256, 256, 288 0           block2b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_dwconv (DepthwiseConv2D (None, 256, 256, 288 2592        block2b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2b_bn (BatchNormalization) (None, 256, 256, 288 1152        block2b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2b_activation (Activation) (None, 256, 256, 288 0           block2b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_squeeze (GlobalAvera (None, 288)          0           block2b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_excite (Multiply)    (None, 256, 256, 288 0           block2b_activation[0][0]         \n",
            "                                                                 block2b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_conv (Conv2D)   (None, 256, 256, 48) 13824       block2b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_bn (BatchNormal (None, 256, 256, 48) 192         block2b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_drop (FixedDropout)     (None, 256, 256, 48) 0           block2b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_add (Add)               (None, 256, 256, 48) 0           block2b_drop[0][0]               \n",
            "                                                                 block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_conv (Conv2D)    (None, 256, 256, 288 13824       block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_bn (BatchNormali (None, 256, 256, 288 1152        block2c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_activation (Acti (None, 256, 256, 288 0           block2c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_dwconv (DepthwiseConv2D (None, 256, 256, 288 2592        block2c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2c_bn (BatchNormalization) (None, 256, 256, 288 1152        block2c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2c_activation (Activation) (None, 256, 256, 288 0           block2c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_squeeze (GlobalAvera (None, 288)          0           block2c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_excite (Multiply)    (None, 256, 256, 288 0           block2c_activation[0][0]         \n",
            "                                                                 block2c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_project_conv (Conv2D)   (None, 256, 256, 48) 13824       block2c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_project_bn (BatchNormal (None, 256, 256, 48) 192         block2c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2c_drop (FixedDropout)     (None, 256, 256, 48) 0           block2c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_add (Add)               (None, 256, 256, 48) 0           block2c_drop[0][0]               \n",
            "                                                                 block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_conv (Conv2D)    (None, 256, 256, 288 13824       block2c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_bn (BatchNormali (None, 256, 256, 288 1152        block2d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_activation (Acti (None, 256, 256, 288 0           block2d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_dwconv (DepthwiseConv2D (None, 256, 256, 288 2592        block2d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2d_bn (BatchNormalization) (None, 256, 256, 288 1152        block2d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2d_activation (Activation) (None, 256, 256, 288 0           block2d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_squeeze (GlobalAvera (None, 288)          0           block2d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_excite (Multiply)    (None, 256, 256, 288 0           block2d_activation[0][0]         \n",
            "                                                                 block2d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_project_conv (Conv2D)   (None, 256, 256, 48) 13824       block2d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_project_bn (BatchNormal (None, 256, 256, 48) 192         block2d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2d_drop (FixedDropout)     (None, 256, 256, 48) 0           block2d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_add (Add)               (None, 256, 256, 48) 0           block2d_drop[0][0]               \n",
            "                                                                 block2c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2e_expand_conv (Conv2D)    (None, 256, 256, 288 13824       block2d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2e_expand_bn (BatchNormali (None, 256, 256, 288 1152        block2e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2e_expand_activation (Acti (None, 256, 256, 288 0           block2e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2e_dwconv (DepthwiseConv2D (None, 256, 256, 288 2592        block2e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2e_bn (BatchNormalization) (None, 256, 256, 288 1152        block2e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2e_activation (Activation) (None, 256, 256, 288 0           block2e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_squeeze (GlobalAvera (None, 288)          0           block2e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2e_se_excite (Multiply)    (None, 256, 256, 288 0           block2e_activation[0][0]         \n",
            "                                                                 block2e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2e_project_conv (Conv2D)   (None, 256, 256, 48) 13824       block2e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2e_project_bn (BatchNormal (None, 256, 256, 48) 192         block2e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2e_drop (FixedDropout)     (None, 256, 256, 48) 0           block2e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2e_add (Add)               (None, 256, 256, 48) 0           block2e_drop[0][0]               \n",
            "                                                                 block2d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2f_expand_conv (Conv2D)    (None, 256, 256, 288 13824       block2e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2f_expand_bn (BatchNormali (None, 256, 256, 288 1152        block2f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2f_expand_activation (Acti (None, 256, 256, 288 0           block2f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2f_dwconv (DepthwiseConv2D (None, 256, 256, 288 2592        block2f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2f_bn (BatchNormalization) (None, 256, 256, 288 1152        block2f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2f_activation (Activation) (None, 256, 256, 288 0           block2f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_squeeze (GlobalAvera (None, 288)          0           block2f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2f_se_excite (Multiply)    (None, 256, 256, 288 0           block2f_activation[0][0]         \n",
            "                                                                 block2f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2f_project_conv (Conv2D)   (None, 256, 256, 48) 13824       block2f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2f_project_bn (BatchNormal (None, 256, 256, 48) 192         block2f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2f_drop (FixedDropout)     (None, 256, 256, 48) 0           block2f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2f_add (Add)               (None, 256, 256, 48) 0           block2f_drop[0][0]               \n",
            "                                                                 block2e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2g_expand_conv (Conv2D)    (None, 256, 256, 288 13824       block2f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2g_expand_bn (BatchNormali (None, 256, 256, 288 1152        block2g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2g_expand_activation (Acti (None, 256, 256, 288 0           block2g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2g_dwconv (DepthwiseConv2D (None, 256, 256, 288 2592        block2g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2g_bn (BatchNormalization) (None, 256, 256, 288 1152        block2g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2g_activation (Activation) (None, 256, 256, 288 0           block2g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_squeeze (GlobalAvera (None, 288)          0           block2g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2g_se_excite (Multiply)    (None, 256, 256, 288 0           block2g_activation[0][0]         \n",
            "                                                                 block2g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2g_project_conv (Conv2D)   (None, 256, 256, 48) 13824       block2g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2g_project_bn (BatchNormal (None, 256, 256, 48) 192         block2g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2g_drop (FixedDropout)     (None, 256, 256, 48) 0           block2g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2g_add (Add)               (None, 256, 256, 48) 0           block2g_drop[0][0]               \n",
            "                                                                 block2f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_conv (Conv2D)    (None, 256, 256, 288 13824       block2g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_bn (BatchNormali (None, 256, 256, 288 1152        block3a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_activation (Acti (None, 256, 256, 288 0           block3a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv (DepthwiseConv2D (None, 128, 128, 288 7200        block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3a_bn (BatchNormalization) (None, 128, 128, 288 1152        block3a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3a_activation (Activation) (None, 128, 128, 288 0           block3a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_squeeze (GlobalAvera (None, 288)          0           block3a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_excite (Multiply)    (None, 128, 128, 288 0           block3a_activation[0][0]         \n",
            "                                                                 block3a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_conv (Conv2D)   (None, 128, 128, 80) 23040       block3a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_bn (BatchNormal (None, 128, 128, 80) 320         block3a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_conv (Conv2D)    (None, 128, 128, 480 38400       block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_bn (BatchNormali (None, 128, 128, 480 1920        block3b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_activation (Acti (None, 128, 128, 480 0           block3b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_dwconv (DepthwiseConv2D (None, 128, 128, 480 12000       block3b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3b_bn (BatchNormalization) (None, 128, 128, 480 1920        block3b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3b_activation (Activation) (None, 128, 128, 480 0           block3b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_squeeze (GlobalAvera (None, 480)          0           block3b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_excite (Multiply)    (None, 128, 128, 480 0           block3b_activation[0][0]         \n",
            "                                                                 block3b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_conv (Conv2D)   (None, 128, 128, 80) 38400       block3b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_bn (BatchNormal (None, 128, 128, 80) 320         block3b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_drop (FixedDropout)     (None, 128, 128, 80) 0           block3b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_add (Add)               (None, 128, 128, 80) 0           block3b_drop[0][0]               \n",
            "                                                                 block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_conv (Conv2D)    (None, 128, 128, 480 38400       block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_bn (BatchNormali (None, 128, 128, 480 1920        block3c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_activation (Acti (None, 128, 128, 480 0           block3c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_dwconv (DepthwiseConv2D (None, 128, 128, 480 12000       block3c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3c_bn (BatchNormalization) (None, 128, 128, 480 1920        block3c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3c_activation (Activation) (None, 128, 128, 480 0           block3c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_squeeze (GlobalAvera (None, 480)          0           block3c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_excite (Multiply)    (None, 128, 128, 480 0           block3c_activation[0][0]         \n",
            "                                                                 block3c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_project_conv (Conv2D)   (None, 128, 128, 80) 38400       block3c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_project_bn (BatchNormal (None, 128, 128, 80) 320         block3c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3c_drop (FixedDropout)     (None, 128, 128, 80) 0           block3c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_add (Add)               (None, 128, 128, 80) 0           block3c_drop[0][0]               \n",
            "                                                                 block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_conv (Conv2D)    (None, 128, 128, 480 38400       block3c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_bn (BatchNormali (None, 128, 128, 480 1920        block3d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_activation (Acti (None, 128, 128, 480 0           block3d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_dwconv (DepthwiseConv2D (None, 128, 128, 480 12000       block3d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3d_bn (BatchNormalization) (None, 128, 128, 480 1920        block3d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3d_activation (Activation) (None, 128, 128, 480 0           block3d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_squeeze (GlobalAvera (None, 480)          0           block3d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_excite (Multiply)    (None, 128, 128, 480 0           block3d_activation[0][0]         \n",
            "                                                                 block3d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_project_conv (Conv2D)   (None, 128, 128, 80) 38400       block3d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_project_bn (BatchNormal (None, 128, 128, 80) 320         block3d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3d_drop (FixedDropout)     (None, 128, 128, 80) 0           block3d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_add (Add)               (None, 128, 128, 80) 0           block3d_drop[0][0]               \n",
            "                                                                 block3c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3e_expand_conv (Conv2D)    (None, 128, 128, 480 38400       block3d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3e_expand_bn (BatchNormali (None, 128, 128, 480 1920        block3e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3e_expand_activation (Acti (None, 128, 128, 480 0           block3e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3e_dwconv (DepthwiseConv2D (None, 128, 128, 480 12000       block3e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3e_bn (BatchNormalization) (None, 128, 128, 480 1920        block3e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3e_activation (Activation) (None, 128, 128, 480 0           block3e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_squeeze (GlobalAvera (None, 480)          0           block3e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3e_se_excite (Multiply)    (None, 128, 128, 480 0           block3e_activation[0][0]         \n",
            "                                                                 block3e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3e_project_conv (Conv2D)   (None, 128, 128, 80) 38400       block3e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3e_project_bn (BatchNormal (None, 128, 128, 80) 320         block3e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3e_drop (FixedDropout)     (None, 128, 128, 80) 0           block3e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3e_add (Add)               (None, 128, 128, 80) 0           block3e_drop[0][0]               \n",
            "                                                                 block3d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3f_expand_conv (Conv2D)    (None, 128, 128, 480 38400       block3e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3f_expand_bn (BatchNormali (None, 128, 128, 480 1920        block3f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3f_expand_activation (Acti (None, 128, 128, 480 0           block3f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3f_dwconv (DepthwiseConv2D (None, 128, 128, 480 12000       block3f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3f_bn (BatchNormalization) (None, 128, 128, 480 1920        block3f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3f_activation (Activation) (None, 128, 128, 480 0           block3f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_squeeze (GlobalAvera (None, 480)          0           block3f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3f_se_excite (Multiply)    (None, 128, 128, 480 0           block3f_activation[0][0]         \n",
            "                                                                 block3f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3f_project_conv (Conv2D)   (None, 128, 128, 80) 38400       block3f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3f_project_bn (BatchNormal (None, 128, 128, 80) 320         block3f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3f_drop (FixedDropout)     (None, 128, 128, 80) 0           block3f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3f_add (Add)               (None, 128, 128, 80) 0           block3f_drop[0][0]               \n",
            "                                                                 block3e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3g_expand_conv (Conv2D)    (None, 128, 128, 480 38400       block3f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3g_expand_bn (BatchNormali (None, 128, 128, 480 1920        block3g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3g_expand_activation (Acti (None, 128, 128, 480 0           block3g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3g_dwconv (DepthwiseConv2D (None, 128, 128, 480 12000       block3g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3g_bn (BatchNormalization) (None, 128, 128, 480 1920        block3g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3g_activation (Activation) (None, 128, 128, 480 0           block3g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_squeeze (GlobalAvera (None, 480)          0           block3g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3g_se_excite (Multiply)    (None, 128, 128, 480 0           block3g_activation[0][0]         \n",
            "                                                                 block3g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3g_project_conv (Conv2D)   (None, 128, 128, 80) 38400       block3g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3g_project_bn (BatchNormal (None, 128, 128, 80) 320         block3g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3g_drop (FixedDropout)     (None, 128, 128, 80) 0           block3g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3g_add (Add)               (None, 128, 128, 80) 0           block3g_drop[0][0]               \n",
            "                                                                 block3f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_conv (Conv2D)    (None, 128, 128, 480 38400       block3g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_bn (BatchNormali (None, 128, 128, 480 1920        block4a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_activation (Acti (None, 128, 128, 480 0           block4a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv (DepthwiseConv2D (None, 64, 64, 480)  4320        block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4a_bn (BatchNormalization) (None, 64, 64, 480)  1920        block4a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4a_activation (Activation) (None, 64, 64, 480)  0           block4a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_squeeze (GlobalAvera (None, 480)          0           block4a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_excite (Multiply)    (None, 64, 64, 480)  0           block4a_activation[0][0]         \n",
            "                                                                 block4a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_conv (Conv2D)   (None, 64, 64, 160)  76800       block4a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_bn (BatchNormal (None, 64, 64, 160)  640         block4a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_activation (Acti (None, 64, 64, 960)  0           block4b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4b_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4b_activation (Activation) (None, 64, 64, 960)  0           block4b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_squeeze (GlobalAvera (None, 960)          0           block4b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_excite (Multiply)    (None, 64, 64, 960)  0           block4b_activation[0][0]         \n",
            "                                                                 block4b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_bn (BatchNormal (None, 64, 64, 160)  640         block4b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_drop (FixedDropout)     (None, 64, 64, 160)  0           block4b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_add (Add)               (None, 64, 64, 160)  0           block4b_drop[0][0]               \n",
            "                                                                 block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_activation (Acti (None, 64, 64, 960)  0           block4c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4c_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4c_activation (Activation) (None, 64, 64, 960)  0           block4c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_squeeze (GlobalAvera (None, 960)          0           block4c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_excite (Multiply)    (None, 64, 64, 960)  0           block4c_activation[0][0]         \n",
            "                                                                 block4c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_bn (BatchNormal (None, 64, 64, 160)  640         block4c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4c_drop (FixedDropout)     (None, 64, 64, 160)  0           block4c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_add (Add)               (None, 64, 64, 160)  0           block4c_drop[0][0]               \n",
            "                                                                 block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_activation (Acti (None, 64, 64, 960)  0           block4d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4d_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4d_activation (Activation) (None, 64, 64, 960)  0           block4d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_squeeze (GlobalAvera (None, 960)          0           block4d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_excite (Multiply)    (None, 64, 64, 960)  0           block4d_activation[0][0]         \n",
            "                                                                 block4d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_project_bn (BatchNormal (None, 64, 64, 160)  640         block4d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4d_drop (FixedDropout)     (None, 64, 64, 160)  0           block4d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_add (Add)               (None, 64, 64, 160)  0           block4d_drop[0][0]               \n",
            "                                                                 block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_activation (Acti (None, 64, 64, 960)  0           block4e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4e_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4e_activation (Activation) (None, 64, 64, 960)  0           block4e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_squeeze (GlobalAvera (None, 960)          0           block4e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_excite (Multiply)    (None, 64, 64, 960)  0           block4e_activation[0][0]         \n",
            "                                                                 block4e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_project_bn (BatchNormal (None, 64, 64, 160)  640         block4e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4e_drop (FixedDropout)     (None, 64, 64, 160)  0           block4e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_add (Add)               (None, 64, 64, 160)  0           block4e_drop[0][0]               \n",
            "                                                                 block4d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_activation (Acti (None, 64, 64, 960)  0           block4f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4f_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4f_activation (Activation) (None, 64, 64, 960)  0           block4f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_squeeze (GlobalAvera (None, 960)          0           block4f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_excite (Multiply)    (None, 64, 64, 960)  0           block4f_activation[0][0]         \n",
            "                                                                 block4f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_project_bn (BatchNormal (None, 64, 64, 160)  640         block4f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4f_drop (FixedDropout)     (None, 64, 64, 160)  0           block4f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_add (Add)               (None, 64, 64, 160)  0           block4f_drop[0][0]               \n",
            "                                                                 block4e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4g_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4g_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4g_expand_activation (Acti (None, 64, 64, 960)  0           block4g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4g_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4g_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4g_activation (Activation) (None, 64, 64, 960)  0           block4g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_squeeze (GlobalAvera (None, 960)          0           block4g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4g_se_excite (Multiply)    (None, 64, 64, 960)  0           block4g_activation[0][0]         \n",
            "                                                                 block4g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4g_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4g_project_bn (BatchNormal (None, 64, 64, 160)  640         block4g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4g_drop (FixedDropout)     (None, 64, 64, 160)  0           block4g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4g_add (Add)               (None, 64, 64, 160)  0           block4g_drop[0][0]               \n",
            "                                                                 block4f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4h_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4h_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4h_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4h_expand_activation (Acti (None, 64, 64, 960)  0           block4h_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4h_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4h_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4h_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4h_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4h_activation (Activation) (None, 64, 64, 960)  0           block4h_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_squeeze (GlobalAvera (None, 960)          0           block4h_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4h_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4h_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4h_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4h_se_excite (Multiply)    (None, 64, 64, 960)  0           block4h_activation[0][0]         \n",
            "                                                                 block4h_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4h_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4h_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4h_project_bn (BatchNormal (None, 64, 64, 160)  640         block4h_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4h_drop (FixedDropout)     (None, 64, 64, 160)  0           block4h_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4h_add (Add)               (None, 64, 64, 160)  0           block4h_drop[0][0]               \n",
            "                                                                 block4g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4i_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4i_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4i_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4i_expand_activation (Acti (None, 64, 64, 960)  0           block4i_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4i_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4i_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4i_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4i_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4i_activation (Activation) (None, 64, 64, 960)  0           block4i_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_squeeze (GlobalAvera (None, 960)          0           block4i_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4i_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4i_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4i_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4i_se_excite (Multiply)    (None, 64, 64, 960)  0           block4i_activation[0][0]         \n",
            "                                                                 block4i_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4i_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4i_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4i_project_bn (BatchNormal (None, 64, 64, 160)  640         block4i_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4i_drop (FixedDropout)     (None, 64, 64, 160)  0           block4i_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4i_add (Add)               (None, 64, 64, 160)  0           block4i_drop[0][0]               \n",
            "                                                                 block4h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4j_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4j_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block4j_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4j_expand_activation (Acti (None, 64, 64, 960)  0           block4j_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4j_dwconv (DepthwiseConv2D (None, 64, 64, 960)  8640        block4j_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4j_bn (BatchNormalization) (None, 64, 64, 960)  3840        block4j_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4j_activation (Activation) (None, 64, 64, 960)  0           block4j_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_squeeze (GlobalAvera (None, 960)          0           block4j_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4j_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4j_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4j_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4j_se_excite (Multiply)    (None, 64, 64, 960)  0           block4j_activation[0][0]         \n",
            "                                                                 block4j_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4j_project_conv (Conv2D)   (None, 64, 64, 160)  153600      block4j_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4j_project_bn (BatchNormal (None, 64, 64, 160)  640         block4j_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4j_drop (FixedDropout)     (None, 64, 64, 160)  0           block4j_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4j_add (Add)               (None, 64, 64, 160)  0           block4j_drop[0][0]               \n",
            "                                                                 block4i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_conv (Conv2D)    (None, 64, 64, 960)  153600      block4j_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_bn (BatchNormali (None, 64, 64, 960)  3840        block5a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_activation (Acti (None, 64, 64, 960)  0           block5a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_dwconv (DepthwiseConv2D (None, 64, 64, 960)  24000       block5a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5a_bn (BatchNormalization) (None, 64, 64, 960)  3840        block5a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5a_activation (Activation) (None, 64, 64, 960)  0           block5a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_squeeze (GlobalAvera (None, 960)          0           block5a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_excite (Multiply)    (None, 64, 64, 960)  0           block5a_activation[0][0]         \n",
            "                                                                 block5a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_conv (Conv2D)   (None, 64, 64, 224)  215040      block5a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_bn (BatchNormal (None, 64, 64, 224)  896         block5a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_activation (Acti (None, 64, 64, 1344) 0           block5b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5b_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5b_activation (Activation) (None, 64, 64, 1344) 0           block5b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_squeeze (GlobalAvera (None, 1344)         0           block5b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5b_activation[0][0]         \n",
            "                                                                 block5b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_bn (BatchNormal (None, 64, 64, 224)  896         block5b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_drop (FixedDropout)     (None, 64, 64, 224)  0           block5b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_add (Add)               (None, 64, 64, 224)  0           block5b_drop[0][0]               \n",
            "                                                                 block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_activation (Acti (None, 64, 64, 1344) 0           block5c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5c_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5c_activation (Activation) (None, 64, 64, 1344) 0           block5c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_squeeze (GlobalAvera (None, 1344)         0           block5c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5c_activation[0][0]         \n",
            "                                                                 block5c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_bn (BatchNormal (None, 64, 64, 224)  896         block5c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5c_drop (FixedDropout)     (None, 64, 64, 224)  0           block5c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_add (Add)               (None, 64, 64, 224)  0           block5c_drop[0][0]               \n",
            "                                                                 block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_activation (Acti (None, 64, 64, 1344) 0           block5d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5d_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5d_activation (Activation) (None, 64, 64, 1344) 0           block5d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_squeeze (GlobalAvera (None, 1344)         0           block5d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5d_activation[0][0]         \n",
            "                                                                 block5d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_project_bn (BatchNormal (None, 64, 64, 224)  896         block5d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5d_drop (FixedDropout)     (None, 64, 64, 224)  0           block5d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_add (Add)               (None, 64, 64, 224)  0           block5d_drop[0][0]               \n",
            "                                                                 block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_activation (Acti (None, 64, 64, 1344) 0           block5e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5e_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5e_activation (Activation) (None, 64, 64, 1344) 0           block5e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_squeeze (GlobalAvera (None, 1344)         0           block5e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5e_activation[0][0]         \n",
            "                                                                 block5e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_project_bn (BatchNormal (None, 64, 64, 224)  896         block5e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5e_drop (FixedDropout)     (None, 64, 64, 224)  0           block5e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_add (Add)               (None, 64, 64, 224)  0           block5e_drop[0][0]               \n",
            "                                                                 block5d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_activation (Acti (None, 64, 64, 1344) 0           block5f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5f_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5f_activation (Activation) (None, 64, 64, 1344) 0           block5f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_squeeze (GlobalAvera (None, 1344)         0           block5f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5f_activation[0][0]         \n",
            "                                                                 block5f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_project_bn (BatchNormal (None, 64, 64, 224)  896         block5f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5f_drop (FixedDropout)     (None, 64, 64, 224)  0           block5f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_add (Add)               (None, 64, 64, 224)  0           block5f_drop[0][0]               \n",
            "                                                                 block5e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5g_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5g_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5g_expand_activation (Acti (None, 64, 64, 1344) 0           block5g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5g_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5g_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5g_activation (Activation) (None, 64, 64, 1344) 0           block5g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_squeeze (GlobalAvera (None, 1344)         0           block5g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5g_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5g_activation[0][0]         \n",
            "                                                                 block5g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5g_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5g_project_bn (BatchNormal (None, 64, 64, 224)  896         block5g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5g_drop (FixedDropout)     (None, 64, 64, 224)  0           block5g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5g_add (Add)               (None, 64, 64, 224)  0           block5g_drop[0][0]               \n",
            "                                                                 block5f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5h_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5h_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5h_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5h_expand_activation (Acti (None, 64, 64, 1344) 0           block5h_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5h_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5h_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5h_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5h_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5h_activation (Activation) (None, 64, 64, 1344) 0           block5h_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_squeeze (GlobalAvera (None, 1344)         0           block5h_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5h_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5h_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5h_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5h_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5h_activation[0][0]         \n",
            "                                                                 block5h_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5h_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5h_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5h_project_bn (BatchNormal (None, 64, 64, 224)  896         block5h_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5h_drop (FixedDropout)     (None, 64, 64, 224)  0           block5h_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5h_add (Add)               (None, 64, 64, 224)  0           block5h_drop[0][0]               \n",
            "                                                                 block5g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5i_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5i_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5i_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5i_expand_activation (Acti (None, 64, 64, 1344) 0           block5i_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5i_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5i_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5i_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5i_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5i_activation (Activation) (None, 64, 64, 1344) 0           block5i_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_squeeze (GlobalAvera (None, 1344)         0           block5i_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5i_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5i_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5i_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5i_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5i_activation[0][0]         \n",
            "                                                                 block5i_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5i_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5i_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5i_project_bn (BatchNormal (None, 64, 64, 224)  896         block5i_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5i_drop (FixedDropout)     (None, 64, 64, 224)  0           block5i_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5i_add (Add)               (None, 64, 64, 224)  0           block5i_drop[0][0]               \n",
            "                                                                 block5h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5j_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5j_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block5j_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5j_expand_activation (Acti (None, 64, 64, 1344) 0           block5j_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5j_dwconv (DepthwiseConv2D (None, 64, 64, 1344) 33600       block5j_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5j_bn (BatchNormalization) (None, 64, 64, 1344) 5376        block5j_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5j_activation (Activation) (None, 64, 64, 1344) 0           block5j_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_squeeze (GlobalAvera (None, 1344)         0           block5j_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5j_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5j_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5j_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5j_se_excite (Multiply)    (None, 64, 64, 1344) 0           block5j_activation[0][0]         \n",
            "                                                                 block5j_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5j_project_conv (Conv2D)   (None, 64, 64, 224)  301056      block5j_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5j_project_bn (BatchNormal (None, 64, 64, 224)  896         block5j_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5j_drop (FixedDropout)     (None, 64, 64, 224)  0           block5j_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5j_add (Add)               (None, 64, 64, 224)  0           block5j_drop[0][0]               \n",
            "                                                                 block5i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_conv (Conv2D)    (None, 64, 64, 1344) 301056      block5j_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_bn (BatchNormali (None, 64, 64, 1344) 5376        block6a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_activation (Acti (None, 64, 64, 1344) 0           block6a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv (DepthwiseConv2D (None, 32, 32, 1344) 33600       block6a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6a_bn (BatchNormalization) (None, 32, 32, 1344) 5376        block6a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6a_activation (Activation) (None, 32, 32, 1344) 0           block6a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_squeeze (GlobalAvera (None, 1344)         0           block6a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block6a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block6a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block6a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_excite (Multiply)    (None, 32, 32, 1344) 0           block6a_activation[0][0]         \n",
            "                                                                 block6a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_conv (Conv2D)   (None, 32, 32, 384)  516096      block6a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_activation (Acti (None, 32, 32, 2304) 0           block6b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6b_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6b_activation (Activation) (None, 32, 32, 2304) 0           block6b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_squeeze (GlobalAvera (None, 2304)         0           block6b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6b_activation[0][0]         \n",
            "                                                                 block6b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_drop (FixedDropout)     (None, 32, 32, 384)  0           block6b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_add (Add)               (None, 32, 32, 384)  0           block6b_drop[0][0]               \n",
            "                                                                 block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_activation (Acti (None, 32, 32, 2304) 0           block6c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6c_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6c_activation (Activation) (None, 32, 32, 2304) 0           block6c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_squeeze (GlobalAvera (None, 2304)         0           block6c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6c_activation[0][0]         \n",
            "                                                                 block6c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6c_drop (FixedDropout)     (None, 32, 32, 384)  0           block6c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_add (Add)               (None, 32, 32, 384)  0           block6c_drop[0][0]               \n",
            "                                                                 block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_activation (Acti (None, 32, 32, 2304) 0           block6d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6d_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6d_activation (Activation) (None, 32, 32, 2304) 0           block6d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_squeeze (GlobalAvera (None, 2304)         0           block6d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6d_activation[0][0]         \n",
            "                                                                 block6d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6d_drop (FixedDropout)     (None, 32, 32, 384)  0           block6d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_add (Add)               (None, 32, 32, 384)  0           block6d_drop[0][0]               \n",
            "                                                                 block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6e_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6e_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6e_expand_activation (Acti (None, 32, 32, 2304) 0           block6e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6e_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6e_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6e_activation (Activation) (None, 32, 32, 2304) 0           block6e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_squeeze (GlobalAvera (None, 2304)         0           block6e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6e_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6e_activation[0][0]         \n",
            "                                                                 block6e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6e_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6e_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6e_drop (FixedDropout)     (None, 32, 32, 384)  0           block6e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6e_add (Add)               (None, 32, 32, 384)  0           block6e_drop[0][0]               \n",
            "                                                                 block6d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6f_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6f_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6f_expand_activation (Acti (None, 32, 32, 2304) 0           block6f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6f_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6f_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6f_activation (Activation) (None, 32, 32, 2304) 0           block6f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_squeeze (GlobalAvera (None, 2304)         0           block6f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6f_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6f_activation[0][0]         \n",
            "                                                                 block6f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6f_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6f_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6f_drop (FixedDropout)     (None, 32, 32, 384)  0           block6f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6f_add (Add)               (None, 32, 32, 384)  0           block6f_drop[0][0]               \n",
            "                                                                 block6e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6g_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6g_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6g_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6g_expand_activation (Acti (None, 32, 32, 2304) 0           block6g_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6g_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6g_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6g_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6g_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6g_activation (Activation) (None, 32, 32, 2304) 0           block6g_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_squeeze (GlobalAvera (None, 2304)         0           block6g_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6g_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6g_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6g_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6g_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6g_activation[0][0]         \n",
            "                                                                 block6g_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6g_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6g_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6g_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6g_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6g_drop (FixedDropout)     (None, 32, 32, 384)  0           block6g_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6g_add (Add)               (None, 32, 32, 384)  0           block6g_drop[0][0]               \n",
            "                                                                 block6f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6h_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6h_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6h_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6h_expand_activation (Acti (None, 32, 32, 2304) 0           block6h_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6h_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6h_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6h_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6h_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6h_activation (Activation) (None, 32, 32, 2304) 0           block6h_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_squeeze (GlobalAvera (None, 2304)         0           block6h_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6h_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6h_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6h_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6h_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6h_activation[0][0]         \n",
            "                                                                 block6h_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6h_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6h_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6h_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6h_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6h_drop (FixedDropout)     (None, 32, 32, 384)  0           block6h_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6h_add (Add)               (None, 32, 32, 384)  0           block6h_drop[0][0]               \n",
            "                                                                 block6g_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6i_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6i_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6i_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6i_expand_activation (Acti (None, 32, 32, 2304) 0           block6i_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6i_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6i_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6i_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6i_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6i_activation (Activation) (None, 32, 32, 2304) 0           block6i_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_squeeze (GlobalAvera (None, 2304)         0           block6i_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6i_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6i_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6i_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6i_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6i_activation[0][0]         \n",
            "                                                                 block6i_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6i_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6i_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6i_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6i_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6i_drop (FixedDropout)     (None, 32, 32, 384)  0           block6i_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6i_add (Add)               (None, 32, 32, 384)  0           block6i_drop[0][0]               \n",
            "                                                                 block6h_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6j_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6j_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6j_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6j_expand_activation (Acti (None, 32, 32, 2304) 0           block6j_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6j_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6j_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6j_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6j_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6j_activation (Activation) (None, 32, 32, 2304) 0           block6j_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_squeeze (GlobalAvera (None, 2304)         0           block6j_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6j_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6j_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6j_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6j_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6j_activation[0][0]         \n",
            "                                                                 block6j_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6j_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6j_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6j_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6j_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6j_drop (FixedDropout)     (None, 32, 32, 384)  0           block6j_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6j_add (Add)               (None, 32, 32, 384)  0           block6j_drop[0][0]               \n",
            "                                                                 block6i_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6k_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6j_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6k_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6k_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6k_expand_activation (Acti (None, 32, 32, 2304) 0           block6k_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6k_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6k_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6k_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6k_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6k_activation (Activation) (None, 32, 32, 2304) 0           block6k_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_squeeze (GlobalAvera (None, 2304)         0           block6k_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6k_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6k_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6k_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6k_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6k_activation[0][0]         \n",
            "                                                                 block6k_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6k_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6k_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6k_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6k_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6k_drop (FixedDropout)     (None, 32, 32, 384)  0           block6k_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6k_add (Add)               (None, 32, 32, 384)  0           block6k_drop[0][0]               \n",
            "                                                                 block6j_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6l_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6k_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6l_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6l_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6l_expand_activation (Acti (None, 32, 32, 2304) 0           block6l_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6l_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6l_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6l_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6l_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6l_activation (Activation) (None, 32, 32, 2304) 0           block6l_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_squeeze (GlobalAvera (None, 2304)         0           block6l_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6l_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6l_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6l_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6l_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6l_activation[0][0]         \n",
            "                                                                 block6l_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6l_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6l_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6l_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6l_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6l_drop (FixedDropout)     (None, 32, 32, 384)  0           block6l_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6l_add (Add)               (None, 32, 32, 384)  0           block6l_drop[0][0]               \n",
            "                                                                 block6k_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6m_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6l_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6m_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block6m_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6m_expand_activation (Acti (None, 32, 32, 2304) 0           block6m_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6m_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 57600       block6m_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6m_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block6m_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6m_activation (Activation) (None, 32, 32, 2304) 0           block6m_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_squeeze (GlobalAvera (None, 2304)         0           block6m_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6m_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6m_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6m_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6m_se_excite (Multiply)    (None, 32, 32, 2304) 0           block6m_activation[0][0]         \n",
            "                                                                 block6m_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6m_project_conv (Conv2D)   (None, 32, 32, 384)  884736      block6m_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6m_project_bn (BatchNormal (None, 32, 32, 384)  1536        block6m_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6m_drop (FixedDropout)     (None, 32, 32, 384)  0           block6m_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6m_add (Add)               (None, 32, 32, 384)  0           block6m_drop[0][0]               \n",
            "                                                                 block6l_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_conv (Conv2D)    (None, 32, 32, 2304) 884736      block6m_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_bn (BatchNormali (None, 32, 32, 2304) 9216        block7a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_activation (Acti (None, 32, 32, 2304) 0           block7a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_dwconv (DepthwiseConv2D (None, 32, 32, 2304) 20736       block7a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7a_bn (BatchNormalization) (None, 32, 32, 2304) 9216        block7a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7a_activation (Activation) (None, 32, 32, 2304) 0           block7a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_squeeze (GlobalAvera (None, 2304)         0           block7a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_excite (Multiply)    (None, 32, 32, 2304) 0           block7a_activation[0][0]         \n",
            "                                                                 block7a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_conv (Conv2D)   (None, 32, 32, 640)  1474560     block7a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_bn (BatchNormal (None, 32, 32, 640)  2560        block7a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7b_expand_conv (Conv2D)    (None, 32, 32, 3840) 2457600     block7a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_expand_bn (BatchNormali (None, 32, 32, 3840) 15360       block7b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7b_expand_activation (Acti (None, 32, 32, 3840) 0           block7b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7b_dwconv (DepthwiseConv2D (None, 32, 32, 3840) 34560       block7b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7b_bn (BatchNormalization) (None, 32, 32, 3840) 15360       block7b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7b_activation (Activation) (None, 32, 32, 3840) 0           block7b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_squeeze (GlobalAvera (None, 3840)         0           block7b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7b_se_excite (Multiply)    (None, 32, 32, 3840) 0           block7b_activation[0][0]         \n",
            "                                                                 block7b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7b_project_conv (Conv2D)   (None, 32, 32, 640)  2457600     block7b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7b_project_bn (BatchNormal (None, 32, 32, 640)  2560        block7b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7b_drop (FixedDropout)     (None, 32, 32, 640)  0           block7b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7b_add (Add)               (None, 32, 32, 640)  0           block7b_drop[0][0]               \n",
            "                                                                 block7a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_expand_conv (Conv2D)    (None, 32, 32, 3840) 2457600     block7b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7c_expand_bn (BatchNormali (None, 32, 32, 3840) 15360       block7c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7c_expand_activation (Acti (None, 32, 32, 3840) 0           block7c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7c_dwconv (DepthwiseConv2D (None, 32, 32, 3840) 34560       block7c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7c_bn (BatchNormalization) (None, 32, 32, 3840) 15360       block7c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7c_activation (Activation) (None, 32, 32, 3840) 0           block7c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_squeeze (GlobalAvera (None, 3840)         0           block7c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7c_se_excite (Multiply)    (None, 32, 32, 3840) 0           block7c_activation[0][0]         \n",
            "                                                                 block7c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7c_project_conv (Conv2D)   (None, 32, 32, 640)  2457600     block7c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7c_project_bn (BatchNormal (None, 32, 32, 640)  2560        block7c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7c_drop (FixedDropout)     (None, 32, 32, 640)  0           block7c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7c_add (Add)               (None, 32, 32, 640)  0           block7c_drop[0][0]               \n",
            "                                                                 block7b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7d_expand_conv (Conv2D)    (None, 32, 32, 3840) 2457600     block7c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7d_expand_bn (BatchNormali (None, 32, 32, 3840) 15360       block7d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7d_expand_activation (Acti (None, 32, 32, 3840) 0           block7d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7d_dwconv (DepthwiseConv2D (None, 32, 32, 3840) 34560       block7d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7d_bn (BatchNormalization) (None, 32, 32, 3840) 15360       block7d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7d_activation (Activation) (None, 32, 32, 3840) 0           block7d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_squeeze (GlobalAvera (None, 3840)         0           block7d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7d_se_excite (Multiply)    (None, 32, 32, 3840) 0           block7d_activation[0][0]         \n",
            "                                                                 block7d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7d_project_conv (Conv2D)   (None, 32, 32, 640)  2457600     block7d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7d_project_bn (BatchNormal (None, 32, 32, 640)  2560        block7d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block7d_drop (FixedDropout)     (None, 32, 32, 640)  0           block7d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7d_add (Add)               (None, 32, 32, 640)  0           block7d_drop[0][0]               \n",
            "                                                                 block7c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "top_conv (Conv2D)               (None, 32, 32, 2560) 1638400     block7d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "top_bn (BatchNormalization)     (None, 32, 32, 2560) 10240       top_conv[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "top_activation (Activation)     (None, 32, 32, 2560) 0           top_bn[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 64,097,680\n",
            "Trainable params: 0\n",
            "Non-trainable params: 64,097,680\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QaZqpZ0Crv3",
        "colab_type": "code",
        "outputId": "c679d515-355d-4d1c-ebbb-801929bf7e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "set_trainable = False\n",
        "for layer in efficient_net.layers:\n",
        "    if layer.name == 'block7a_expand_conv':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "for layer in efficient_net.layers:\n",
        "    if layer.trainable == True:\n",
        "        print('yeah baby!')\n",
        "    else:\n",
        "      print('naah! :(')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "naah! :(\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n",
            "yeah baby!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm2kjXQtXzOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW1m6Wgpas_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "B = tf.keras.backend\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + B.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n",
        "\n",
        "@tf.function\n",
        "def fast_gelu(x):\n",
        "    return B.hard_sigmoid(1.702 * x) * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjdewVi7ks55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def swish(x, beta=1.0):\n",
        "    return x * K.sigmoid(beta * x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d8vQiao2C7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-yNzKfjKRTt",
        "colab_type": "text"
      },
      "source": [
        "AveragePooling + Flatten\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY4ZPZbl6ElT",
        "colab_type": "code",
        "outputId": "e25d8a20-2987-428f-b0ff-53fa1dd24932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##CNN + FC 256 x 1 + AP + FLatten + Leakyrelu\n",
        "model = Sequential()\n",
        "model.add(efficient_net)\n",
        "model.add(AveragePooling2D(pool_size=(4, 4)))\n",
        "model.add(Flatten(name=\"flatten\"))\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Dense(units = 8192))\n",
        "#model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
        "#model.add(Dropout(0.4))\n",
        "model.add(Dense(units = 256))\n",
        "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units = 3, activation ='softmax'))\n",
        "opt = adam(lr=0.00001, amsgrad=True)\n",
        "model.compile(optimizer= opt, loss='categorical_crossentropy', metrics=['accuracy',f1_m,precision_m, recall_m]) #sparse_categorical_crossentropy for sequence\n",
        "saver = keras.callbacks.ModelCheckpoint('/content/cnnfcfinal.h5', save_best_only=True, monitor='val_acc', mode='max', save_weights_only=False, period=1)\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "model.fit_generator(train_generator, callbacks=[saver], steps_per_epoch=STEP_SIZE_TRAIN, validation_steps=STEP_SIZE_VALID, epochs=5000, validation_data = validation_generator, use_multiprocessing=True)\n",
        "##Epoch 353/5000\n",
        "##20/20 [==============================] - 53s 3s/step - loss: 0.0106 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 0.6171 - val_acc: 0.9000 - val_f1_m: 0.9000 - val_precision_m: 0.9000 - val_recall_m: 0.9000"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5000\n",
            "20/20 [==============================] - 80s 4s/step - loss: 1.0079 - acc: 0.5687 - f1_m: 0.5421 - precision_m: 0.5955 - recall_m: 0.5061 - val_loss: 0.8918 - val_acc: 0.4375 - val_f1_m: 0.4446 - val_precision_m: 0.4521 - val_recall_m: 0.4375\n",
            "Epoch 2/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.7041 - acc: 0.7188 - f1_m: 0.7126 - precision_m: 0.7568 - recall_m: 0.6750 - val_loss: 0.7308 - val_acc: 0.6500 - val_f1_m: 0.6267 - val_precision_m: 0.6571 - val_recall_m: 0.6000\n",
            "Epoch 3/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.6013 - acc: 0.7841 - f1_m: 0.7716 - precision_m: 0.7959 - recall_m: 0.7498 - val_loss: 0.7952 - val_acc: 0.5000 - val_f1_m: 0.4597 - val_precision_m: 0.4700 - val_recall_m: 0.4500\n",
            "Epoch 4/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.4227 - acc: 0.8529 - f1_m: 0.8495 - precision_m: 0.8807 - recall_m: 0.8217 - val_loss: 0.8205 - val_acc: 0.4688 - val_f1_m: 0.4914 - val_precision_m: 0.5167 - val_recall_m: 0.4688\n",
            "Epoch 5/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.3780 - acc: 0.8719 - f1_m: 0.8682 - precision_m: 0.8896 - recall_m: 0.8501 - val_loss: 0.7854 - val_acc: 0.6500 - val_f1_m: 0.6161 - val_precision_m: 0.6333 - val_recall_m: 0.6000\n",
            "Epoch 6/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.4053 - acc: 0.8781 - f1_m: 0.8762 - precision_m: 0.9014 - recall_m: 0.8531 - val_loss: 1.1033 - val_acc: 0.4500 - val_f1_m: 0.4500 - val_precision_m: 0.4500 - val_recall_m: 0.4500\n",
            "Epoch 7/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.3413 - acc: 0.8752 - f1_m: 0.8809 - precision_m: 0.9043 - recall_m: 0.8595 - val_loss: 0.8250 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 8/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.3992 - acc: 0.8842 - f1_m: 0.8731 - precision_m: 0.8954 - recall_m: 0.8531 - val_loss: 0.8750 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 9/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.2899 - acc: 0.8877 - f1_m: 0.8862 - precision_m: 0.9051 - recall_m: 0.8689 - val_loss: 0.9041 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 10/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.3914 - acc: 0.8814 - f1_m: 0.8762 - precision_m: 0.8915 - recall_m: 0.8626 - val_loss: 0.8129 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 11/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.3349 - acc: 0.8780 - f1_m: 0.8821 - precision_m: 0.8967 - recall_m: 0.8686 - val_loss: 0.9743 - val_acc: 0.4500 - val_f1_m: 0.4500 - val_precision_m: 0.4500 - val_recall_m: 0.4500\n",
            "Epoch 12/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.2422 - acc: 0.9250 - f1_m: 0.9181 - precision_m: 0.9242 - recall_m: 0.9125 - val_loss: 0.8365 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 13/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.2945 - acc: 0.8971 - f1_m: 0.9014 - precision_m: 0.9131 - recall_m: 0.8908 - val_loss: 0.8101 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 14/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.2387 - acc: 0.9185 - f1_m: 0.9196 - precision_m: 0.9345 - recall_m: 0.9060 - val_loss: 0.7817 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 15/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1862 - acc: 0.9312 - f1_m: 0.9341 - precision_m: 0.9404 - recall_m: 0.9281 - val_loss: 0.8596 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 16/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.2414 - acc: 0.9093 - f1_m: 0.9046 - precision_m: 0.9164 - recall_m: 0.8938 - val_loss: 0.8200 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 17/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.2636 - acc: 0.9062 - f1_m: 0.9102 - precision_m: 0.9179 - recall_m: 0.9030 - val_loss: 0.7848 - val_acc: 0.6000 - val_f1_m: 0.6359 - val_precision_m: 0.6800 - val_recall_m: 0.6000\n",
            "Epoch 18/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1697 - acc: 0.9563 - f1_m: 0.9576 - precision_m: 0.9623 - recall_m: 0.9531 - val_loss: 0.6301 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 19/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.2258 - acc: 0.9124 - f1_m: 0.9072 - precision_m: 0.9118 - recall_m: 0.9030 - val_loss: 0.8537 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 20/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.2254 - acc: 0.9312 - f1_m: 0.9295 - precision_m: 0.9413 - recall_m: 0.9187 - val_loss: 1.4217 - val_acc: 0.4000 - val_f1_m: 0.4000 - val_precision_m: 0.4000 - val_recall_m: 0.4000\n",
            "Epoch 21/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.1659 - acc: 0.9531 - f1_m: 0.9510 - precision_m: 0.9557 - recall_m: 0.9468 - val_loss: 0.6896 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 22/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1264 - acc: 0.9687 - f1_m: 0.9670 - precision_m: 0.9685 - recall_m: 0.9656 - val_loss: 1.0643 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 23/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1472 - acc: 0.9406 - f1_m: 0.9362 - precision_m: 0.9451 - recall_m: 0.9280 - val_loss: 1.1458 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 24/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1592 - acc: 0.9438 - f1_m: 0.9449 - precision_m: 0.9527 - recall_m: 0.9375 - val_loss: 0.8585 - val_acc: 0.7000 - val_f1_m: 0.7177 - val_precision_m: 0.7367 - val_recall_m: 0.7000\n",
            "Epoch 25/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1870 - acc: 0.9441 - f1_m: 0.9421 - precision_m: 0.9466 - recall_m: 0.9378 - val_loss: 1.2674 - val_acc: 0.5938 - val_f1_m: 0.6028 - val_precision_m: 0.6125 - val_recall_m: 0.5938\n",
            "Epoch 26/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1948 - acc: 0.9346 - f1_m: 0.9324 - precision_m: 0.9443 - recall_m: 0.9222 - val_loss: 0.7476 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 27/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1851 - acc: 0.9344 - f1_m: 0.9340 - precision_m: 0.9369 - recall_m: 0.9312 - val_loss: 1.0015 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 28/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1699 - acc: 0.9439 - f1_m: 0.9386 - precision_m: 0.9464 - recall_m: 0.9314 - val_loss: 1.0247 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 29/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1263 - acc: 0.9531 - f1_m: 0.9497 - precision_m: 0.9527 - recall_m: 0.9469 - val_loss: 1.2134 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 30/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.1801 - acc: 0.9283 - f1_m: 0.9311 - precision_m: 0.9374 - recall_m: 0.9251 - val_loss: 0.9355 - val_acc: 0.6500 - val_f1_m: 0.6145 - val_precision_m: 0.6300 - val_recall_m: 0.6000\n",
            "Epoch 31/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.1319 - acc: 0.9563 - f1_m: 0.9556 - precision_m: 0.9651 - recall_m: 0.9470 - val_loss: 1.4039 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 32/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.1449 - acc: 0.9562 - f1_m: 0.9559 - precision_m: 0.9589 - recall_m: 0.9531 - val_loss: 1.3189 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 33/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1243 - acc: 0.9500 - f1_m: 0.9498 - precision_m: 0.9529 - recall_m: 0.9469 - val_loss: 0.9845 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 34/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1815 - acc: 0.9281 - f1_m: 0.9296 - precision_m: 0.9312 - recall_m: 0.9281 - val_loss: 1.1755 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 35/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.1519 - acc: 0.9500 - f1_m: 0.9500 - precision_m: 0.9500 - recall_m: 0.9500 - val_loss: 1.3924 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 36/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.1114 - acc: 0.9718 - f1_m: 0.9718 - precision_m: 0.9718 - recall_m: 0.9718 - val_loss: 1.1695 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 37/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1288 - acc: 0.9471 - f1_m: 0.9470 - precision_m: 0.9502 - recall_m: 0.9439 - val_loss: 1.1642 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 38/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0820 - acc: 0.9750 - f1_m: 0.9715 - precision_m: 0.9779 - recall_m: 0.9656 - val_loss: 0.9527 - val_acc: 0.7500 - val_f1_m: 0.6876 - val_precision_m: 0.7333 - val_recall_m: 0.6500\n",
            "Epoch 39/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.1318 - acc: 0.9531 - f1_m: 0.9544 - precision_m: 0.9593 - recall_m: 0.9499 - val_loss: 1.4691 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 40/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.1169 - acc: 0.9563 - f1_m: 0.9576 - precision_m: 0.9625 - recall_m: 0.9532 - val_loss: 1.1367 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 41/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1340 - acc: 0.9470 - f1_m: 0.9468 - precision_m: 0.9499 - recall_m: 0.9438 - val_loss: 0.8351 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 42/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0823 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 1.0827 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 43/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.1246 - acc: 0.9499 - f1_m: 0.9493 - precision_m: 0.9522 - recall_m: 0.9468 - val_loss: 1.2750 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 44/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0850 - acc: 0.9656 - f1_m: 0.9671 - precision_m: 0.9688 - recall_m: 0.9656 - val_loss: 1.2806 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 45/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.1016 - acc: 0.9687 - f1_m: 0.9671 - precision_m: 0.9687 - recall_m: 0.9656 - val_loss: 1.1085 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 46/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0991 - acc: 0.9781 - f1_m: 0.9764 - precision_m: 0.9812 - recall_m: 0.9718 - val_loss: 1.1990 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 47/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0747 - acc: 0.9781 - f1_m: 0.9825 - precision_m: 0.9873 - recall_m: 0.9781 - val_loss: 0.9619 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 48/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0734 - acc: 0.9844 - f1_m: 0.9843 - precision_m: 0.9875 - recall_m: 0.9812 - val_loss: 1.8437 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 49/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0859 - acc: 0.9812 - f1_m: 0.9796 - precision_m: 0.9812 - recall_m: 0.9781 - val_loss: 1.3959 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 50/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0701 - acc: 0.9750 - f1_m: 0.9718 - precision_m: 0.9750 - recall_m: 0.9688 - val_loss: 1.0825 - val_acc: 0.7000 - val_f1_m: 0.6661 - val_precision_m: 0.6833 - val_recall_m: 0.6500\n",
            "Epoch 51/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.1334 - acc: 0.9530 - f1_m: 0.9528 - precision_m: 0.9559 - recall_m: 0.9499 - val_loss: 1.1515 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 52/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0825 - acc: 0.9718 - f1_m: 0.9734 - precision_m: 0.9750 - recall_m: 0.9718 - val_loss: 1.3210 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 53/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0578 - acc: 0.9844 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 0.6363 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 54/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0830 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 1.7512 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 55/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0966 - acc: 0.9844 - f1_m: 0.9843 - precision_m: 0.9875 - recall_m: 0.9812 - val_loss: 1.1159 - val_acc: 0.6250 - val_f1_m: 0.6351 - val_precision_m: 0.6458 - val_recall_m: 0.6250\n",
            "Epoch 56/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0575 - acc: 0.9718 - f1_m: 0.9733 - precision_m: 0.9748 - recall_m: 0.9718 - val_loss: 1.4659 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 57/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0736 - acc: 0.9812 - f1_m: 0.9796 - precision_m: 0.9812 - recall_m: 0.9781 - val_loss: 0.8204 - val_acc: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 58/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0789 - acc: 0.9781 - f1_m: 0.9730 - precision_m: 0.9775 - recall_m: 0.9687 - val_loss: 1.2449 - val_acc: 0.6562 - val_f1_m: 0.6361 - val_precision_m: 0.6479 - val_recall_m: 0.6250\n",
            "Epoch 59/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0808 - acc: 0.9781 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9781 - val_loss: 1.3597 - val_acc: 0.5500 - val_f1_m: 0.5629 - val_precision_m: 0.5767 - val_recall_m: 0.5500\n",
            "Epoch 60/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0559 - acc: 0.9845 - f1_m: 0.9845 - precision_m: 0.9845 - recall_m: 0.9845 - val_loss: 0.9770 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 61/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0759 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - val_loss: 1.2254 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 62/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0657 - acc: 0.9844 - f1_m: 0.9842 - precision_m: 0.9873 - recall_m: 0.9812 - val_loss: 0.6209 - val_acc: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 63/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0533 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 1.5853 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 64/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0910 - acc: 0.9687 - f1_m: 0.9671 - precision_m: 0.9687 - recall_m: 0.9656 - val_loss: 1.1333 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 65/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0774 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - val_loss: 1.1715 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 66/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0470 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 1.2201 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 67/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0812 - acc: 0.9687 - f1_m: 0.9687 - precision_m: 0.9687 - recall_m: 0.9687 - val_loss: 1.0384 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 68/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0972 - acc: 0.9656 - f1_m: 0.9671 - precision_m: 0.9687 - recall_m: 0.9656 - val_loss: 1.7579 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 69/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0660 - acc: 0.9844 - f1_m: 0.9810 - precision_m: 0.9841 - recall_m: 0.9781 - val_loss: 0.8437 - val_acc: 0.7500 - val_f1_m: 0.7694 - val_precision_m: 0.7900 - val_recall_m: 0.7500\n",
            "Epoch 70/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0627 - acc: 0.9812 - f1_m: 0.9827 - precision_m: 0.9844 - recall_m: 0.9812 - val_loss: 1.1623 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 71/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.1041 - acc: 0.9593 - f1_m: 0.9593 - precision_m: 0.9593 - recall_m: 0.9593 - val_loss: 1.6131 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 72/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0674 - acc: 0.9783 - f1_m: 0.9798 - precision_m: 0.9814 - recall_m: 0.9783 - val_loss: 0.8627 - val_acc: 0.7500 - val_f1_m: 0.7677 - val_precision_m: 0.7867 - val_recall_m: 0.7500\n",
            "Epoch 73/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.1037 - acc: 0.9656 - f1_m: 0.9654 - precision_m: 0.9685 - recall_m: 0.9625 - val_loss: 1.4293 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 74/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0729 - acc: 0.9749 - f1_m: 0.9749 - precision_m: 0.9749 - recall_m: 0.9749 - val_loss: 2.0572 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 75/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0564 - acc: 0.9844 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 0.9523 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 76/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0631 - acc: 0.9781 - f1_m: 0.9765 - precision_m: 0.9781 - recall_m: 0.9750 - val_loss: 1.3584 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 77/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0526 - acc: 0.9844 - f1_m: 0.9826 - precision_m: 0.9875 - recall_m: 0.9783 - val_loss: 1.1285 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 78/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0669 - acc: 0.9688 - f1_m: 0.9656 - precision_m: 0.9688 - recall_m: 0.9627 - val_loss: 1.4106 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 79/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0508 - acc: 0.9720 - f1_m: 0.9735 - precision_m: 0.9751 - recall_m: 0.9720 - val_loss: 1.4847 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 80/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0555 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 1.6576 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 81/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0580 - acc: 0.9815 - f1_m: 0.9815 - precision_m: 0.9815 - recall_m: 0.9815 - val_loss: 0.9857 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 82/5000\n",
            "20/20 [==============================] - 56s 3s/step - loss: 0.0573 - acc: 0.9781 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9781 - val_loss: 1.6496 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 83/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0862 - acc: 0.9718 - f1_m: 0.9718 - precision_m: 0.9718 - recall_m: 0.9718 - val_loss: 0.6818 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 84/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0537 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 1.8779 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 85/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0642 - acc: 0.9719 - f1_m: 0.9719 - precision_m: 0.9719 - recall_m: 0.9719 - val_loss: 1.1432 - val_acc: 0.6562 - val_f1_m: 0.6653 - val_precision_m: 0.6750 - val_recall_m: 0.6562\n",
            "Epoch 86/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0682 - acc: 0.9782 - f1_m: 0.9766 - precision_m: 0.9782 - recall_m: 0.9751 - val_loss: 1.3291 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 87/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0650 - acc: 0.9781 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9781 - val_loss: 1.1316 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 88/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0651 - acc: 0.9656 - f1_m: 0.9655 - precision_m: 0.9688 - recall_m: 0.9625 - val_loss: 1.2447 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 89/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0965 - acc: 0.9596 - f1_m: 0.9596 - precision_m: 0.9596 - recall_m: 0.9596 - val_loss: 1.7961 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 90/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0706 - acc: 0.9781 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9781 - val_loss: 1.0465 - val_acc: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 91/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0450 - acc: 0.9844 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 1.5989 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 92/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0523 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 1.0777 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 93/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0520 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.8162 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 94/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0569 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 1.4005 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 95/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0474 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 1.7067 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 96/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0642 - acc: 0.9718 - f1_m: 0.9734 - precision_m: 0.9750 - recall_m: 0.9718 - val_loss: 1.2450 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 97/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0594 - acc: 0.9750 - f1_m: 0.9718 - precision_m: 0.9750 - recall_m: 0.9688 - val_loss: 1.5650 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 98/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0502 - acc: 0.9875 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 1.3831 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 99/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0822 - acc: 0.9626 - f1_m: 0.9626 - precision_m: 0.9626 - recall_m: 0.9626 - val_loss: 1.1825 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 100/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0505 - acc: 0.9844 - f1_m: 0.9827 - precision_m: 0.9844 - recall_m: 0.9812 - val_loss: 1.4632 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 101/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0738 - acc: 0.9656 - f1_m: 0.9670 - precision_m: 0.9685 - recall_m: 0.9656 - val_loss: 1.2750 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 102/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0783 - acc: 0.9718 - f1_m: 0.9718 - precision_m: 0.9718 - recall_m: 0.9718 - val_loss: 1.6532 - val_acc: 0.6000 - val_f1_m: 0.6161 - val_precision_m: 0.6333 - val_recall_m: 0.6000\n",
            "Epoch 103/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0778 - acc: 0.9781 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9781 - val_loss: 1.8374 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 104/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0231 - acc: 0.9937 - f1_m: 0.9920 - precision_m: 0.9935 - recall_m: 0.9906 - val_loss: 1.0197 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 105/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0397 - acc: 0.9845 - f1_m: 0.9845 - precision_m: 0.9845 - recall_m: 0.9845 - val_loss: 1.3444 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 106/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0512 - acc: 0.9812 - f1_m: 0.9827 - precision_m: 0.9844 - recall_m: 0.9812 - val_loss: 2.0186 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 107/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0469 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 0.6959 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 108/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0598 - acc: 0.9844 - f1_m: 0.9827 - precision_m: 0.9844 - recall_m: 0.9812 - val_loss: 1.5634 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 109/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0490 - acc: 0.9906 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 1.5037 - val_acc: 0.6562 - val_f1_m: 0.6361 - val_precision_m: 0.6479 - val_recall_m: 0.6250\n",
            "Epoch 110/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0566 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 2.0356 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 111/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0489 - acc: 0.9906 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 1.1846 - val_acc: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 112/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0618 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.4458 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 113/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0320 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.2581 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 114/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0248 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.7386 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 115/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0315 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.7569 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 116/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0519 - acc: 0.9843 - f1_m: 0.9843 - precision_m: 0.9843 - recall_m: 0.9843 - val_loss: 1.0709 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 117/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0338 - acc: 0.9937 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 2.4144 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 118/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0501 - acc: 0.9751 - f1_m: 0.9765 - precision_m: 0.9780 - recall_m: 0.9751 - val_loss: 1.5377 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 119/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0650 - acc: 0.9814 - f1_m: 0.9829 - precision_m: 0.9845 - recall_m: 0.9814 - val_loss: 2.1096 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 120/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0243 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.0776 - val_acc: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 121/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0206 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.3516 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 122/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0348 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.8730 - val_acc: 0.6000 - val_f1_m: 0.5645 - val_precision_m: 0.5800 - val_recall_m: 0.5500\n",
            "Epoch 123/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0852 - acc: 0.9593 - f1_m: 0.9593 - precision_m: 0.9593 - recall_m: 0.9593 - val_loss: 1.5444 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 124/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0269 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.8085 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 125/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0363 - acc: 0.9875 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 1.2681 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 126/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0325 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.4698 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 127/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0508 - acc: 0.9875 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 1.8177 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 128/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0347 - acc: 0.9906 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 1.2271 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 129/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0928 - acc: 0.9720 - f1_m: 0.9720 - precision_m: 0.9720 - recall_m: 0.9720 - val_loss: 1.5274 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 130/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0633 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - val_loss: 1.5489 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 131/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0445 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.1958 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 132/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0450 - acc: 0.9875 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 2.2722 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 133/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0377 - acc: 0.9937 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.9007 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 134/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0329 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 1.8402 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 135/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0391 - acc: 0.9843 - f1_m: 0.9843 - precision_m: 0.9843 - recall_m: 0.9843 - val_loss: 1.4306 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 136/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0287 - acc: 0.9937 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.8889 - val_acc: 0.6562 - val_f1_m: 0.6351 - val_precision_m: 0.6458 - val_recall_m: 0.6250\n",
            "Epoch 137/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0314 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 1.4565 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 138/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0289 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.9806 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 139/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0194 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.9670 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 140/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0365 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.8582 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 141/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0361 - acc: 0.9906 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 1.6963 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 142/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0303 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.6467 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 143/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0275 - acc: 0.9937 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 2.1788 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 144/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0400 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.3149 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 145/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0539 - acc: 0.9781 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9781 - val_loss: 1.2710 - val_acc: 0.7188 - val_f1_m: 0.7187 - val_precision_m: 0.7188 - val_recall_m: 0.7188\n",
            "Epoch 146/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0394 - acc: 0.9844 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 2.2384 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 147/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0387 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.8102 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 148/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0210 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.9235 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 149/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0379 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.9569 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 150/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0402 - acc: 0.9875 - f1_m: 0.9889 - precision_m: 0.9904 - recall_m: 0.9875 - val_loss: 1.3162 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 151/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0245 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.8919 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 152/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0293 - acc: 0.9875 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 1.4231 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 153/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0293 - acc: 0.9937 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 1.4648 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 154/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0319 - acc: 0.9906 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 1.4576 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 155/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0494 - acc: 0.9843 - f1_m: 0.9843 - precision_m: 0.9843 - recall_m: 0.9843 - val_loss: 1.7755 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 156/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0357 - acc: 0.9875 - f1_m: 0.9858 - precision_m: 0.9873 - recall_m: 0.9844 - val_loss: 1.3376 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 157/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0219 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.3149 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 158/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0744 - acc: 0.9656 - f1_m: 0.9685 - precision_m: 0.9717 - recall_m: 0.9656 - val_loss: 1.5467 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 159/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0333 - acc: 0.9845 - f1_m: 0.9874 - precision_m: 0.9906 - recall_m: 0.9845 - val_loss: 2.0218 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 160/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0286 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.5980 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 161/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0259 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 2.0262 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 162/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0394 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.7342 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 163/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0166 - acc: 1.0000 - f1_m: 0.9984 - precision_m: 1.0000 - recall_m: 0.9969 - val_loss: 1.4796 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 164/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0219 - acc: 0.9969 - f1_m: 0.9935 - precision_m: 0.9967 - recall_m: 0.9906 - val_loss: 2.1125 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 165/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0223 - acc: 0.9969 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 2.2049 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 166/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0429 - acc: 0.9783 - f1_m: 0.9765 - precision_m: 0.9780 - recall_m: 0.9751 - val_loss: 1.6724 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 167/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0169 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 2.5589 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 168/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0206 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.6589 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 169/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0413 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 2.1247 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 170/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0276 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.5083 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 171/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0337 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.7622 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 172/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0379 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.5098 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 173/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0415 - acc: 0.9906 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 2.4381 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 174/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0250 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.2770 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 175/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0498 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 2.1178 - val_acc: 0.6250 - val_f1_m: 0.6341 - val_precision_m: 0.6438 - val_recall_m: 0.6250\n",
            "Epoch 176/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0304 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.3037 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 177/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0559 - acc: 0.9781 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9781 - val_loss: 1.7018 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 178/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0313 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.8225 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 179/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0297 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.4992 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 180/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0326 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 2.1547 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 181/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0264 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.7365 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 182/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0319 - acc: 0.9844 - f1_m: 0.9874 - precision_m: 0.9906 - recall_m: 0.9844 - val_loss: 1.5843 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 183/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0222 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.0385 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 184/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0557 - acc: 0.9815 - f1_m: 0.9815 - precision_m: 0.9815 - recall_m: 0.9815 - val_loss: 1.6685 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 185/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0205 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 2.7728 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 186/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0857 - acc: 0.9753 - f1_m: 0.9737 - precision_m: 0.9753 - recall_m: 0.9721 - val_loss: 1.6614 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 187/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0629 - acc: 0.9812 - f1_m: 0.9827 - precision_m: 0.9844 - recall_m: 0.9812 - val_loss: 1.6314 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 188/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0377 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.9378 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 189/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0595 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 1.5211 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 190/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0329 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 2.2052 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 191/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0373 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.9275 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 192/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0271 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.3951 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 193/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0524 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 1.5458 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 194/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0426 - acc: 0.9906 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 2.0181 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 195/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0368 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.5855 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 196/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0469 - acc: 0.9781 - f1_m: 0.9763 - precision_m: 0.9777 - recall_m: 0.9750 - val_loss: 1.5458 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 197/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0331 - acc: 0.9875 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9843 - val_loss: 1.8794 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 198/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0280 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.4797 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 199/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0153 - acc: 1.0000 - f1_m: 0.9984 - precision_m: 1.0000 - recall_m: 0.9969 - val_loss: 1.7168 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 200/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0501 - acc: 0.9906 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 2.1038 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 201/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0286 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.6368 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 202/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0327 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.8501 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 203/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0263 - acc: 0.9906 - f1_m: 0.9920 - precision_m: 0.9935 - recall_m: 0.9906 - val_loss: 2.0540 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 204/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0299 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.6390 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 205/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0276 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.5966 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 206/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0674 - acc: 0.9687 - f1_m: 0.9687 - precision_m: 0.9687 - recall_m: 0.9687 - val_loss: 1.6969 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 207/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0543 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 1.5967 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 208/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0307 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.8507 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 209/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0165 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.0916 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 210/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0362 - acc: 0.9906 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 0.9353 - val_acc: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 211/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0277 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.6103 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 212/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0165 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.2709 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 213/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0222 - acc: 0.9906 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 1.9839 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 214/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0115 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.6120 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 215/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0464 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.9647 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 216/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0299 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.7322 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 217/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0295 - acc: 0.9906 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 1.5695 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 218/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0151 - acc: 0.9969 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 2.2735 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 219/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0469 - acc: 0.9812 - f1_m: 0.9795 - precision_m: 0.9810 - recall_m: 0.9781 - val_loss: 1.2264 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 220/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0295 - acc: 0.9875 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 1.4343 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 221/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0157 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.1519 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 222/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0200 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.4401 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 223/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0166 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.7385 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 224/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0292 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.2511 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 225/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0267 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 1.2712 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 226/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0202 - acc: 0.9937 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.9916 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 227/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0254 - acc: 0.9937 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 1.3747 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 228/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0137 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.7995 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 229/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0144 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.6421 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 230/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0332 - acc: 0.9937 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.8737 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 231/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0118 - acc: 0.9969 - f1_m: 0.9984 - precision_m: 1.0000 - recall_m: 0.9969 - val_loss: 1.8234 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 232/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0181 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.9147 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 233/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0239 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.5875 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 234/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0181 - acc: 0.9969 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.6750 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 235/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0179 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.5954 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 236/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0173 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.2261 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 237/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0180 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.2615 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 238/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0468 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 1.8766 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 239/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0269 - acc: 0.9906 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 2.0182 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 240/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0239 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.4601 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 241/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0411 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.5528 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 242/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0273 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 2.3466 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 243/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0169 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.4316 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 244/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0372 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.3822 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 245/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0259 - acc: 0.9937 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 2.0012 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 246/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0088 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.6200 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 247/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0106 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.7930 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 248/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0120 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.6938 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 249/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0175 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.5428 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 250/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0386 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.5763 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 251/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0182 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.0606 - val_acc: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 252/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0206 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 2.3077 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 253/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0124 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.7519 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 254/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0289 - acc: 0.9906 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 1.2373 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 255/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0221 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.8500 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 256/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0168 - acc: 0.9937 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.8904 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 257/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0217 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.9976 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 258/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0438 - acc: 0.9812 - f1_m: 0.9827 - precision_m: 0.9843 - recall_m: 0.9812 - val_loss: 1.2123 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 259/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0226 - acc: 0.9937 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 1.6311 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 260/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0388 - acc: 0.9875 - f1_m: 0.9858 - precision_m: 0.9873 - recall_m: 0.9844 - val_loss: 2.4704 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 261/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0160 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.6977 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 262/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0133 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 2.0486 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 263/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0328 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 2.1259 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 264/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0100 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 0.7012 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 265/5000\n",
            "20/20 [==============================] - 56s 3s/step - loss: 0.0329 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.7071 - val_acc: 0.7188 - val_f1_m: 0.7187 - val_precision_m: 0.7188 - val_recall_m: 0.7188\n",
            "Epoch 266/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0523 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 2.4266 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 267/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0241 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.7253 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 268/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0426 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 1.7676 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 269/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0278 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 2.1618 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 270/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0122 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.5623 - val_acc: 0.6500 - val_f1_m: 0.6571 - val_precision_m: 0.6667 - val_recall_m: 0.6500\n",
            "Epoch 271/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0388 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 1.5873 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 272/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0363 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.9124 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 273/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0212 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.5656 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 274/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0379 - acc: 0.9845 - f1_m: 0.9845 - precision_m: 0.9845 - recall_m: 0.9845 - val_loss: 1.4597 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 275/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0142 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.2551 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 276/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0233 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.0684 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 277/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0150 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.3825 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 278/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0223 - acc: 0.9875 - f1_m: 0.9905 - precision_m: 0.9937 - recall_m: 0.9875 - val_loss: 0.8279 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 279/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0509 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 3.0142 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 280/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0156 - acc: 0.9939 - f1_m: 0.9967 - precision_m: 1.0000 - recall_m: 0.9939 - val_loss: 2.0182 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 281/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0300 - acc: 0.9845 - f1_m: 0.9860 - precision_m: 0.9876 - recall_m: 0.9845 - val_loss: 2.1425 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 282/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0453 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.7678 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 283/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0093 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.9568 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 284/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0258 - acc: 0.9875 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 2.0053 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 285/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0119 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.9624 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 286/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0232 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.8257 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 287/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0253 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.5146 - val_acc: 0.4500 - val_f1_m: 0.4500 - val_precision_m: 0.4500 - val_recall_m: 0.4500\n",
            "Epoch 288/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0460 - acc: 0.9906 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 0.6392 - val_acc: 0.9000 - val_f1_m: 0.9000 - val_precision_m: 0.9000 - val_recall_m: 0.9000\n",
            "Epoch 289/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0227 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.7213 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 290/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0093 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4845 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 291/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0225 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.9295 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 292/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0176 - acc: 0.9969 - f1_m: 0.9984 - precision_m: 1.0000 - recall_m: 0.9969 - val_loss: 2.0345 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 293/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0227 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.5578 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 294/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0097 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.7699 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 295/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0308 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 2.0123 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 296/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0386 - acc: 0.9875 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 1.5499 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 297/5000\n",
            " 1/20 [>.............................] - ETA: 23s - loss: 3.0850e-04 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0259 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 1.3757 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 298/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0201 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.0682 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 299/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0181 - acc: 0.9937 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.3273 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 300/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0252 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.2879 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 301/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0183 - acc: 0.9969 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.7997 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 302/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0214 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.6622 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 303/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0245 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 2.7761 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 304/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0147 - acc: 0.9937 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.7462 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 305/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0204 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.9886 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 306/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0235 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.5978 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 307/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0078 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.8591 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 308/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0158 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.6198 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 309/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0255 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.7670 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 310/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0352 - acc: 0.9939 - f1_m: 0.9923 - precision_m: 0.9939 - recall_m: 0.9908 - val_loss: 2.0774 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 311/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0179 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.6961 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 312/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0148 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.2563 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 313/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0202 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.7831 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 314/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0185 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.2476 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 315/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0240 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 2.0980 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 316/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0185 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.8400 - val_acc: 0.5625 - val_f1_m: 0.5625 - val_precision_m: 0.5625 - val_recall_m: 0.5625\n",
            "Epoch 317/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0536 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 1.2313 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 318/5000\n",
            " 1/20 [>.............................] - ETA: 46s - loss: 0.0059 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0140 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.0958 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 319/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0152 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.9755 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 320/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0279 - acc: 0.9875 - f1_m: 0.9874 - precision_m: 0.9906 - recall_m: 0.9844 - val_loss: 2.5754 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 321/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0168 - acc: 0.9969 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.0515 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 322/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0119 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.9078 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 323/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0335 - acc: 0.9875 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 3.0698 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 324/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0336 - acc: 0.9875 - f1_m: 0.9890 - precision_m: 0.9906 - recall_m: 0.9875 - val_loss: 1.3180 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 325/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0304 - acc: 0.9875 - f1_m: 0.9859 - precision_m: 0.9875 - recall_m: 0.9844 - val_loss: 2.1621 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 326/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0137 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.8215 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 327/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0132 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.4947 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 328/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0079 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 2.3508 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 329/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0130 - acc: 0.9969 - f1_m: 0.9984 - precision_m: 1.0000 - recall_m: 0.9969 - val_loss: 2.3536 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 330/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0173 - acc: 0.9969 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.4294 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 331/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0255 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.5077 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 332/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0093 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.5652 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 333/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0185 - acc: 0.9876 - f1_m: 0.9892 - precision_m: 0.9908 - recall_m: 0.9876 - val_loss: 2.1088 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 334/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0177 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 2.0078 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 335/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0614 - acc: 0.9783 - f1_m: 0.9783 - precision_m: 0.9783 - recall_m: 0.9783 - val_loss: 1.8694 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 336/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0129 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 2.2082 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 337/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0108 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.3658 - val_acc: 0.5938 - val_f1_m: 0.5937 - val_precision_m: 0.5938 - val_recall_m: 0.5938\n",
            "Epoch 338/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0208 - acc: 0.9906 - f1_m: 0.9921 - precision_m: 0.9937 - recall_m: 0.9906 - val_loss: 1.8703 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 339/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0162 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.6012 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 340/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0072 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.9228 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 341/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0125 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.2901 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 342/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0119 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.3682 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 343/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0227 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.0947 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 344/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0116 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.0521 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 345/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0194 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 3.0843 - val_acc: 0.4500 - val_f1_m: 0.4500 - val_precision_m: 0.4500 - val_recall_m: 0.4500\n",
            "Epoch 346/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0219 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.8569 - val_acc: 0.6875 - val_f1_m: 0.6875 - val_precision_m: 0.6875 - val_recall_m: 0.6875\n",
            "Epoch 347/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0178 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.3145 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 348/5000\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.0140 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.2325 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 349/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0116 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.8461 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 350/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0329 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.0363 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 351/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0261 - acc: 0.9906 - f1_m: 0.9920 - precision_m: 0.9935 - recall_m: 0.9906 - val_loss: 1.8019 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 352/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0073 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 2.0523 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 353/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0106 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 0.6171 - val_acc: 0.9000 - val_f1_m: 0.9000 - val_precision_m: 0.9000 - val_recall_m: 0.9000\n",
            "Epoch 354/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0133 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 2.6191 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 355/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0257 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 1.4315 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 356/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0323 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 2.0983 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 357/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0068 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5045 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 358/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0121 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 1.7751 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 359/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0085 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4586 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 360/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0175 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.1149 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 361/5000\n",
            "20/20 [==============================] - 55s 3s/step - loss: 0.0079 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2199 - val_acc: 0.7188 - val_f1_m: 0.7187 - val_precision_m: 0.7188 - val_recall_m: 0.7188\n",
            "Epoch 362/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0179 - acc: 0.9937 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 1.7612 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 363/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0284 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 2.3449 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 364/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0176 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 1.8434 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 365/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0140 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.0836 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 366/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0171 - acc: 0.9969 - f1_m: 0.9953 - precision_m: 0.9969 - recall_m: 0.9937 - val_loss: 2.4327 - val_acc: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
            "Epoch 367/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0105 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.0331 - val_acc: 0.7188 - val_f1_m: 0.7187 - val_precision_m: 0.7188 - val_recall_m: 0.7188\n",
            "Epoch 368/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0108 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.2569 - val_acc: 0.5500 - val_f1_m: 0.5500 - val_precision_m: 0.5500 - val_recall_m: 0.5500\n",
            "Epoch 369/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0120 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.2649 - val_acc: 0.6000 - val_f1_m: 0.6000 - val_precision_m: 0.6000 - val_recall_m: 0.6000\n",
            "Epoch 370/5000\n",
            "20/20 [==============================] - 53s 3s/step - loss: 0.0175 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 1.9590 - val_acc: 0.6562 - val_f1_m: 0.6562 - val_precision_m: 0.6562 - val_recall_m: 0.6562\n",
            "Epoch 371/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0125 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.8258 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 372/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0073 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2141 - val_acc: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
            "Epoch 373/5000\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.0233 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 1.6742 - val_acc: 0.7188 - val_f1_m: 0.7187 - val_precision_m: 0.7188 - val_recall_m: 0.7188\n",
            "Epoch 374/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0163 - acc: 0.9969 - f1_m: 0.9969 - precision_m: 0.9969 - recall_m: 0.9969 - val_loss: 2.6768 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 375/5000\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.0206 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 2.1204 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 376/5000\n",
            "20/20 [==============================] - 54s 3s/step - loss: 0.0088 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 2.0214 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 377/5000\n",
            "18/20 [==========================>...] - ETA: 4s - loss: 0.0168 - acc: 0.9965 - f1_m: 0.9965 - precision_m: 0.9965 - recall_m: 0.9965"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-677:\n",
            "Process ForkPoolWorker-676:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-708246941e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m## train max == 0.9594 val == 0.8000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZYDrotWJcVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##CNN + FC II"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_dmBTJOI6gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##CNN + PCA + SVM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFZWIKz3I99Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##CNN + PCA + KNN"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}